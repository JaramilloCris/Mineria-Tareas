---
title: "Tarea 1: Exploración y Visualización de Datos"
author: "Felipe Bravo, Hernán Sarmiento, Aymé Arango, Alison Fernandez, Cinthia Mabel Sanchez, Juan Pablo Silva"
date: "Septiembre 2020"
output:
  html_document:
    number_sections: yes
    theme: spacelab
    toc: yes
  pdf_document:
    toc: yes
---

# Declaración de compromiso ético
Nosotros **AGREGUEN SUS NOMBRES**, declaramos que realizamos de manera grupal los pasos de la presente actividad. También declaramos no incurrir en copia, ni compartir nuestras respuestas con otras personas ni con otros grupos. Por lo que, ratificamos que las respuestas son de nuestra propia confección y reflejan nuestro propio conocimiento.

# Instrucciones

1. Trabajen en equipos de dos o tres personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.

2. Modifique este archivo `.Rmd` agregando sus respuestas donde corresponda.

3. Para cada pregunta, cuando corresponda, **incluya el código fuente que utilizó para llegar a su respuesta**.

4. El formato de entrega para esta actividad es un archivo html. **Genere un archivo HTML usando RStudio** y súbalo a U-Cursos.
   Basta con que uno de los integrantes haga la entrega. Si ambos hacen una entrega en U-Cursos, se revisará cualquiera de éstas.

# Tarea 
La primera parte de esta actividad son preguntas teóricas que avanzaron en las clases del curso de Minería de datos.

## Teoría

*1. ¿Cuál es el objetivo de Minería de datos y qué la diferencia de Machine Learning? De un ejemplo.*

**Respuesta:**

El objetivo de la minería de datos es generar conocimiento o patrones desconocidos a partir de grandes volúmenes de datos.
A partir de estos datos se extrae información y se transforma en una estructura comprensible de la cual se extraigan conocimientos. Por otro lado el machine learning crea sistemas que puedan aprender automáticamente, generan predicciones.

Un asistente de texto automatico en una pagina web:

Machine Learning: A partir de los mensajes que le llegan del usuario, el programa predice que debe responder y de que forma.

Minería: A partir de muchas muestras de datos (conversaciones del este programa) podemos ver si esta funcionando correctamente o no y a que factores se debe.


*2. Describa y compare los siguientes métodos usados en Minería de datos: clasificación vs. clustering.*

**Respuesta:**

Clasificación:

Tiene un set de entrenamiento de atributos enfocados en clases. Se modelan en atributo clase. Se enfoca principalmente en clasificar datos nuevos asignándoles la clase más correcta, es decir, se tiene un set de datos que poseen atributos y se agrupan por clases (tienen atributos similares), luego llegan nuevos datos a los que se les debe asignar una clase de estas que se encuentran en el dataset.

Clustering:

Se tiene datos con un set de atributos y cierta semejanza entre si, su objetivo es encontrar conjuntos similares entre sí y también conjuntos que no tengan muchas similitudes.

En clasificación llegan datos sin una clase y se le asigna dependiendo sus atributos, mientras que clustering busca buscar semejanzas o diferencias entre grupos de datos.


*3. ¿Qué desafios existen en Minería de datos?*

**Respuesta:**

Dentro de los desafios actuales que podemos encontrar hoy en dia en Mineria de Datos se encuentran: 

- Escalabilidad: Nuestro modelo sobre los datos funcione tanto a baja escala como a alta.

- Dimensionalidad: Podemos generar un modelo que tengas muchas caracterisiticas pero generar metodos eficiente sobre todas esas caracteristicas y que encuentre patrones reales puede llegar a ser muy costoso. Por otro lado puede que nuestro modelo tenga muy pocas dimensiones y no nos permite predecir o describir correctamente los datos.

- Datos complejos y heterogeneos: Datos sin una estructura definida (no estructurada) o datos que sean muy distintos entre si y que no permiten encontrar un patron o caracterisistica que nos permita describir los datos correctamente.

- Calidad de los datos: Los datos pueden que no esten de la forma que uno quisiera, puede que falten datos, no esten estructurados de la forma correcta, que exista desbalances en los datos generando analisis incorerectos, etc. 

- Distribucion de los datos y propiedad

- Privacidad

- Streaming: Muchos de los datos que se encuentran en la red son flujos de datos, lo que signfica que son grandes volumenes de datos probablemente no estructurados y como consecuencia su costo de adquision sea muy alto.


*4. Respecto a los tipos de atributo, ¿cuál es la diferencia entre razón e intervalo?*

**Respuesta:**

En razón tenemos un "cero", en decir, existe un valor minimo (o valor absoluto minimo) de toda la escala, en cambio en los intervalos no tenemos un rango especificado, podemos tener valores tanto negativos como positivos. Por otro lado los datos de tipo razon tienen la operacion de producto y division, operacion que los intervalos no tienen.


*5. ¿Qué factores que ocasionan errores en el análisis de datos deben ser considerados para la limpieza de un set de datos?*

**Respuesta:**

Los factores que ocasionan errores son los siguientes:

- Ruido y outliers
- Valores faltantes
- Datos duplicados


*6. ¿Qué es el análisis exploratorio de datos o EDA?*

**Respuesta:**

Es un conjunto de tecnicas para comprender de manera rapida la naturaleza de una coleccion de datos o dataset, basada principalmente en dos criterios: Las estadisticas de resumen y la visualizacion de datos.


*7. Describa las medidas de tendencia central: media y mediana. Exponga la diferencia entre ambas.*

**Respuesta:**

Media:

Es el promedio de todos los elementos, en otras palabras es la suma de todos los elementos divido en el total.

Mediana:

Teniendo todos los elementos de alguna observacion ordenados de menor a mayor la mediana representa la posicion central que separa la mitad inferior y superior de dichas observaciones, es decir, es el valor que esta justo en medio de todas esas observaciones.

Una de las principales diferencias es que la media es muy sensible a los outliers, en cambio la mediana mucho mas robusta al ruido.


*8. ¿Qué es una matriz de correlación y para qué sirve?*

**Respuesta:**

Es una matriz que contiene en sus celdas el coeficiente de correlacion para cada par de variables numericas con un valor entre -1 y 1. Nos sirve para saber como se comportan las variables entre ellas, por ejemplo, si dos variables tienen un valor cercano a 1 significa que si una crece la otra tambien lo hara, en caso contrario si es cercano a -1 tenemos una relacion inversa. Si la correlacion es cercana a 0 tenenos independencia entre ambas variables.


*9. Explique cómo se construye un Boxplot y exponga cómo se identifican los valores atípicos u outliers en este tipo de gráfico.*

**Respuesta:**

Los Bloxplot se construyen a partir de los percentiles. Se hace un rectangulo con el pirmer y tercer cuartil dividiendo dicho cuadrdado por la mitad usando la mediana. La altura de este rectangulo es la resta estre los cuantiles anteriores
$Q_3 - Q_1$ (RIC) que se utiliza para proyectar una recta por ambos extremos de largo: $Q_1 - 1.5 \cdot RIC$ (recta inferior) y $Q_3 + 1.5 \cdot RIC$ (recta superior), si un valor es mas extremo que el largo de alguno de los brazos se consideran atípicos u outliers.


## Práctica 

En esta parte de la actividad se trabajará con los datos del Proceso Constituyente 2016-2017 publicados en el Portal de Datos Abiertos del Gobierno de Chile, para mayor información pueden ingresar al siguiente link: https://datos.gob.cl/dataset/proceso-constituyente-abierto-a-la-ciudadania. Los datos corresponden a las actas de los Encuentros Locales Autoconvocados (ELAs), en cada cual, un grupo de personas se reune a discutir distintos conceptos como por ejemplo: salud, educación, seguridad, etc.

Los datos con los que trabajarán consisten en la cantidad de veces que cada concepto constitucional fue mencionado por cada localidad de Chile. 

Para cargar los datos, use:

```{r}
data_tf <- read.csv("http://dcc.uchile.cl/~hsarmien/mineria/datasets/actas.txt", header = T)
```

**Por cada pregunta adjunte el código R que utilizó para llegar a la respuesta. Respuestas sin código no recibirán puntaje**

### Exploración básica

1. ¿Cuáles son las dimensiones del dataset (filas, columnas)? Adjunte código o indique cómo determinó la cantidad de datos total. 

```{r}
nrow(data_tf)
ncol(data_tf)
#Filas = 328
#Columnas = 113
```


2. ¿Qué describe cada línea del dataset? (ejemplifique tomando la fila 85)

```{r}
data_tf[85,]
# Cada fila del dataset representa la participación de localidades en distintos conceptos. La primera columna
# de la fila se presenta el nombre del lugar donde se tomaron los datos y las demas columnas son numeros enteros que 
# entregan el grado de participación de esa localidad en distintos puntos (huelga, educación, etc).

# Por ejemplo para el caso de la fila 85, su localidad es Coquimbo/Elqui/Andacollo, donde hubo 0 mención a huelga, 1 mención de eduación, etc
```

3. ¿Existen localidades repetidas en el dataset? Adjunte el código o indique cómo llegó a esa conclusión. 

```{r}
data <- data_tf %>%
  group_by(localidad)

nrow(data_tf)
nrow(data)

#Al crear un dataframe agrupando las localidades y calculando sus filas, se aprecia que son la misma cantidad
#Que el dataframe sin agrupar, por lo que no existen localidades repetidas
```

4. Liste los nombres de las columnas del dataset `data_tf`. Adjunte código en R y *recuerde* usar `head` si el resultado es muy largo.

```{r}
head(names(data_tf))
```


### Análisis

1. Liste todas las localidades donde *no* se discutió el concepto `a_la_salud`. 

```{r}
data_tf[data_tf$a_la_salud==0, "localidad"]
```

2. Liste las 10 localidades que más mencionaron el concepto `justicia`. 

```{r}
d <- data_tf[order(data_tf$justicia, decreasing = TRUE), "localidad"]
d[0:10]
```


3. Liste los 10 conceptos menos mencionados a lo largo de todo el proceso.


```{r}
d <- colSums(data_tf[,-1])
cantidad <- d[order(d, decreasing = FALSE)]
d <- data.frame(cantidad)
nombres <- names(cantidad)
nombres[0:10]
```


4. Liste las 10 localidades que más participaron en el proceso. Describa cómo definió su medida de participación.


```{r}
d <- rowSums(data_tf[,-1])
d <- data.frame(localidad=data_tf[,"localidad"], cantidad=d)
d <- d[order(d$cantidad, decreasing = TRUE), "localidad"]
d[0:10]

```

5. Ejecute el siguiente código que permitirá agregar una nueva columna a nuestro dataframe que solo tendrá el nombre de la región.

```{r, message = F, warning=F}
library(dplyr)
regiones <- strsplit(as.character(data_tf[,1]), '/')
data_tf$region <- sapply(regiones, "[[", 1)
data_tf <- data_tf %>% select(localidad, region, everything())
```

Luego, genere un gráfico de barras (ggplot) que muestre los 10 conceptos más mencionados en cada una de las regiones mencionadas (adjunte gráficos y código):

- `Atacama`
- `Coquimbo`
- `Metropolitana de Santiago`


Cabe resaltar, que se esperan tres gráficos de barras para las tres diferentes regiones:

```{r}
# 10 conceptos más mencionados en Atacama
atacama_df <- data_tf[data_tf$region == "Atacama",]
nombres <- names(atacama_df[,-2:-1])
new_data <- data.frame(concepto = nombres, total = colSums(atacama_df[,-2:-1]))
new_data <- new_data[order(new_data$total, decreasing = TRUE),]
new_data <- new_data[0:10,]

library(ggplot2)  # cargamos la librería

ggplot(new_data) +   # asociamos un data frame a ggplot
  geom_bar(aes(x = concepto, y = total), stat="identity") +
  coord_flip() +
  ggtitle("10 conceptos más mencionados en Atacama") +
  xlab("Concepto") + ylab("Frecuencia (cantidad)") 

```

```{r}
# 10 conceptos más mencionados en Coquimbo
coquimbo_df <- data_tf[data_tf$region == "Coquimbo",]
nombres <- names(coquimbo_df[,-2:-1])
new_data <- data.frame(concepto = nombres, total = colSums(coquimbo_df[,-2:-1]))
new_data <- new_data[order(new_data$total, decreasing = TRUE),]
new_data <- new_data[0:10,]

library(ggplot2)  # cargamos la librería

ggplot(new_data) +   # asociamos un data frame a ggplot
  geom_bar(aes(x = concepto, y = total), stat="identity") +
  coord_flip() +
  ggtitle("10 conceptos más mencionados en Coquimbo") +
  xlab("Concepto") + ylab("Frecuencia (cantidad)") 
```

```{r}
# 10 conceptos más mencionados en Metropolitana de Santiago
santiago_df <- data_tf[data_tf$region == "Metropolitana de Santiago",]
nombres <- names(santiago_df[,-2:-1])
new_data <- data.frame(concepto = nombres, total = colSums(santiago_df[,-2:-1]))
new_data <- new_data[order(new_data$total, decreasing = TRUE),]
new_data <- new_data[0:10,]

library(ggplot2)  # cargamos la librería

ggplot(new_data) +   # asociamos un data frame a ggplot
  geom_bar(aes(x = concepto, y = total), stat="identity") +
  coord_flip() +
  ggtitle("10 conceptos más mencionados en Santiago") +
  xlab("Concepto") + ylab("Frecuencia (cantidad)") 
```

6. De la pregunta anterior, ¿considera que es razonable usar el conteo de frecuencias para determinar las regiones que tuvieron mayor participación en el proceso? ¿Por qué? Sugiera y solamente comente una forma distinta de hacerlo.

```{r}
# RESPUESTA
```

## Ejercicios

### Accidentes de tránsito

Para esta sección utilizaremos un dataset real de número de accidentes de tránsito por localidad, el cual puede ser encontrado en el siguiente link: http://datos.gob.cl/dataset/9348. Para cargar el dataset ejecute el siguiente código:

```{r}
tipos <- read.table("https://users.dcc.uchile.cl/~hsarmien/mineria/datasets/accidentes_2010_2011.txt")
head(tipos)
```

Explore el set de datos para responder las siguientes preguntas:

1. Filtre los datos para incluir sólo los accidentes ocurridos el año 2011 a nivel regional. Genere un boxplot donde se indique la cantidad de accidentes categorizado por tipo de accidente.

Este tipo de gráfico nos ayudará a entender como se distribuye los datos por cada tipo de accidentes. Es decir, podremos apreciar que tan dispersos o similares son los datos en todo el dataset. También, puede ser útil para observar valores atípicos u outliers en los datos.

```{r}
# RESPUESTA
```

2. ¿Qué aprecia con el gráfico anterior? ¿Qué otra forma de explorar los datos podría agregar? ¿Qué información adicional aporta? Adjunte una breve explicación.

**Respuesta:**

### Diamantes

Considere el set de datos diamonds del paquete ggplot2 de R, que contiene los precios en dolares, junto con otros atributos importantes: quilates, corte, color y claridad. También hay medidas físicas como ser: x (largo), y (ancho), z (profundidad), depth (porcentaje total de profundidad) y table (ancho desde el tope del diamante al punto relativo más ancho del diamante):

```{r}
library(ggplot2)
data("diamonds")
head(diamonds)
```

Realice una exploración por el set de datos para responder las siguientes preguntas:

1. Teniendo en cuenta las medidas físicas, ¿considera que existen valores inexistentes o inconsistentes? Describa como manejaría esta situación. Adjunte el código necesario.

```{r}
# RESPUESTA
summary(diamonds) # resumen para ver diferencias entre pmedia y mediana, observandose que no existen diferencias muy grandes.
sapply(diamonds, function(x) sum(is.na(x))) # se observa que no existen valores faltantes
unique(diamonds) # se puede observar que existen filas duplicadas
```

```{r}
# 1
# Al hacer un bloxplot de los atributos fisicos se observa una cantidad considerable de outliers
boxplot(x = diamonds[c("x","y","z")], ylim=c(0,11), main = "Bloxplot (x,y,z)")

```

```{r}
# 1
# En particular en el atributo depth es bastante mayor esta cantidad de outliers y con cierta simentria en torno al boxplot.
boxplot(x = diamonds[c("depth", "table")],ylim=c(50,75), main = "depth and table")
```

2. Considerando la relación entre dos atributos, ¿qué atributos están más correlacionadas con el precio (price) y qué significa esto? ¿cuál es la correlación más alta para table? Adjunte el código necesario para la respuesta.

```{r}
# RESPUESTA
# - precio: Numericamente al hacer una matriz de correlacion se tiene que las dimensiones del diamante (x,y,z) afectan directamente el valor del este (fuertemente correlacionados), esto quiere decir que si un diamante es mas largo, ancho o profundo su precio sera mayor, lo cual es razonable al tratarse de un diamante mas grande.
# - table: En general se tienen correlaciones mas cercana a 0 que a 1/-1 pero la mas alta seria el atributo "x" que tiene una correlacion positiva debil, por otro lado, el atributo "depth" tiene una correlacion negativa con table un poco mas fuerte que "x".
cor(diamonds[,5:10])

```


3. Proponga otra forma para explorar los datos. ¿Qué información adicional aporta? Adjunte una breve explicación.

**Respuesta:**

Inspirado en la pregunta anterior, donde se busca correlacion en los atributos fisicos de un diamante y su precio, se puede explorar la distribucion del precio pero no en base a otro dato numerico si no en base a los datos categoricos, por ejemplo que tanto afecta el gusto de las personas en el color de un diamante y su precio o si la claridad o corte del diamante afectan la valorizacion que tenga este. Esta distribucion se puede visualizar en un boxplot donde cada caja representaria un color, corte o claridad.
